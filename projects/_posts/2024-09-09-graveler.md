---
title: Playing a billion games of pokemon in a second
catagory: projects misc
tags: optimisation quick-project challenge
layout: post
---

My entry into [the Graveler programming challenge](https://piped.video/watch?v=M8C8dHQE2Ro), has managed to simulate more than the required one billion runs in about 0.3 seconds on my laptop. This is the story of how I built it.

## ~~shoddy~~ naive implementation

Since I have been doing a bunch of programming in rust lately I decided to use it for this little challenge. Here is the naive implementation from [Austin](https://github.com/arhourigan/graveler/blob/main/graveler.py) translated to rust.

```rust
use rand::Rng;

fn main() {
  let mut rng = rand::thread_rng();
  let mut ones = 0;
  let mut max_ones = 0;
  // Constant defined for easier editing when we go up to one billion
  const LIMIT: u64 = 1_000_000;
  for _ in 0..LIMIT {
    for _ in 0..231 {
      let rand_number: u8 = rng.gen();
      // Since rand_number can be anything from [0,255] we take the
      //[modulo](https://simple.wikipedia.org/wiki/Modulation_(mathematics)) of 4 to evenly distribute
      // results between [0, 1, 2, 3] (each having a 25% chance)
      if rand_number % 4 == 1 {
        ones += 1;
      }
    }
    if ones > max_ones {
      max_ones = ones;
    }
    ones = 0;
  }

  println!("Highest Ones Roll: {}", ones);
  println!("Number of Roll Sessions: {}", LIMIT);
}
```

Note: until mentioned this program will use one million simulations per run to speed up testing.

This took about 1.5s to run. 1500 seconds, or 25 minutes, for one billion, (hence limiting it to one million). But since you are almost certainly using different hardware I won't mention these times, instead each version will

## Need for Speed: XorShift

Since the most expensive call in the hot path is generating random numbers, and we don't need cryptographically secure random numbers, we can roll our own <abbr title="PseudoRandom Number Generator">PRNG</abbr>. It looks like a [XorShift](https://en.wikipedia.org/wiki/Xorshift) PRNG may be our fastest method.

Here is the code for generating random numbers, based on [this C code](https://en.wikipedia.org/wiki/Xorshift#Example_implementation) (Example for 64-bit word of state)

```rust
struct QuickRng {
  state: u64,
  pointer: u8,
}

impl QuickRng {
  pub fn next_state(&mut self) {
    // Here we xor the state with itself shifted around a small amount.
    // Meaning that the state of most bits depends on three bits
    // (bits at index - 7, index + 9 and index + 9 - 7) in the previous state.
    self.state ^= self.state << 7;
    self.state ^= self.state >> 9;
  }

  pub fn next_digit(&mut self) -> u8 {
    // Get the next unread crumb
    let result = self.state & (0b11 << self.pointer) >> self.pointer;
    // If this word has been used up
    if self.pointer >= 64 {
      // reset pointer and generate a new state
      self.pointer = 0;
      self.next_state();
    } else {
      // otherwise just increment the crumb we are looking at.
      self.pointer += 2;
    }
    return result as u8;
  }
}
```

Here we are further breaking down the 64 bits of state into 32 random numbers between zero (`0b00`) and three (`0b11`) inclusive. This way we require generating random numbers less frequently. Line 15 gets us our random crumb (two bits/ones-or-zeros), then lines 17-24 regenerate the random state and pointer as needed.

And here is the main loop, identical lines removed for brevity:

```rust
fn main() {
  // ...
  let mut quick_rng = QuickRng {
    pointer: 0,
    // Use more expensive random number generator just once for initial state,
    // this will break if the random number is zero however that is a very
    // slim chance (a 2^-64 chance)
    state: rng.gen(),
  };

  for _ in 0..LIMIT {
    for _ in 0..231 {
      // Get the next random number with our fancy new XorShift PRNG
      let rand_number: u8 = quick_rng.next_digit();

      // Since rand_number will be one of [0,1,2,3] we don't need to modulo it anymore.
      if rand_number == 0 {
        ones += 1;
      }
    }
    //...
  }
  //...
}
```

This resulted in `10×` speedup. For reference speedup will be measured in `previous version time / current version time`, so bigger numbers are better, and any number less than one means the change made the implementation **slower**.

## Multiplexing

The random number generator is still taking too much time, we can speed this up further with the help of the **AND** operator (`&`). To explain how let's take a look at an unrelated table.
Since each bit is random, it should have a fifty fifty chance of being either a one or a zero. From this fact we can generate a probability table with one bit of the left input in the columns and one bit of the right input in the rows.

| ----: | :----: | :----: |
| | _`0`_ | _`1`_ |
| _`0`_ | `0.25` | `0.25` |
| _`1`_ | `0.25` | `0.25` |

Here we see that there is a 25% chance of any of the possible outcomes. That's fantastic, we need exactly a 25% (or one in four) chance for paralysis to trigger. But the tricky part is how are we going to quickly check if we got just one of these results? That's where the **AND** operator is going to come in. Let's take a look at its truth table:

| :---- | :---: | :---: |
| _`&`_ | _`0`_ | _`1`_ |
| _`0`_ | `0` | `0` |
| _`1`_ | `0` | `1` |

This is a truth table, its top row represents one bit of input on the left side of the and operator, the first column represents the same bit of input in the right side of the operator. We can see that there is only one case where the result bit is one; when both of the input bits are one, hence the name.

Rust also has a handy function, [count ones](https://doc.rust-lang.org/std/primitive.i64.html#method.count_ones). Which uses some [black magic](https://stackoverflow.com/questions/62926287/how-is-count-ones-implemented-in-rust#answer-62927160) to count how many bits are ones in a 64 bit number in a frighteningly quick manner.

"What is so scary about counting ones quickly?" I hear you ask. Well that's because it allows us to simulate about _64_ turns as quickly as it took the previous implementation to simulate one, because we don't need a lot of the overhead required by using subsections of the state each time.

Here is our new PRNG

```rust
struct QuickRng {
  state: u64,
}

impl QuickRng {
  pub fn next_state(&mut self) {
    self.state ^= self.state << 7;
    self.state ^= self.state >> 9;
  }

  pub fn get_state(&mut self) -> u64 {
    let result = self.state;
    self.next_state();
    return result;

    // So much less code I can add an ASCII horse, and still use fewer lines
    // ,~~_
    // |/\ =_ _ ~
    // _( )_( )\~~
    // \,\  _|\ \~~~
    //    \`   \
  }
}
```

Finally the main code:

```rust
fn main() {
  // ...
  let mut rng1 = QuickRng { state: rng.gen() };
  let mut rng2 = QuickRng { state: rng.gen() };

  for _ in 0..LIMIT {
    // Since we are now rolling 64 random numbers at a time we can only use
    // 3 random numbers before we do something special.
    for _ in 0..3 {
      // By anding two random numbers we have a 25% chance of having a 1
      // for any bit, therefore the count of ones is the number of "ones rolled"
      // on a four sided dice.
      let state = rng1.get_state() & rng2.get_state();
      ones += state.count_ones();
    }

    // Last one is special because we only check 39 bits (That's what the 0x7F_FF_FF_FF_FF is for)
    let state = rng1.get_state() & rng2.get_state() & 0x7F_FF_FF_FF_FF;
    ones += state.count_ones();

    //...
  }
  //...
}
```

The end result is a `18.75×` speedup. On my laptop that is _eight milliseconds_ to simulate a million games. I think we are ready to take on the trillion games that the challenge called for.

## One Trillion Games

Here we are just going to change the value of `LIMIT` to `1_000_000_000`, so our speedup is going to be a disappointing, but expected `0.0001×`, one thousand times slower. But, it is fortunately still finishing in around 6.7s on my laptop. Now we can see the finish line lets implement some easy speedups.

## Easy pickings

Here is a couple of easy speedups that we can do now that we are on the home stretch.

- Multithreading
- Link Time Optimisation
- CPU specific instructions

### So many threads we might as well be a fitted sheet

Modern <abbr title="Central Processing Unit">CPU</abbr>s have these nifty things called cores that allow them to work on many things (called threads) at the same time, and rust has this nifty crate (like a library or plugin) called rayon that allows for easy creation of these threads on different computers with different numbers of cores.

This will result in a drastic change to the `main` function:

```rust
fn main() {
  const LIMIT: u64 = 1_000_000_000;
  let thread_count: usize = std::thread::available_parallelism().unwrap().into();

  // Add one here so we will definitely simulate *at least* a billion games.
  // Since rounding errors could result in fewer games.
  let step_size = LIMIT / thread_count + 1;

  // Create a list of items equal in length to the number of available threads.
  let max_ones = (0..thread_count)
    // Let rayon do its magic and split them into work pools
    .into_par_iter()
    // Do the simulating
    .map(|_| check_n_games(step_size))
    // Get the maximum number of ones rolled between the threads
    .max()
    // Return 0 if all threads panicked for some reason.
    .unwrap_or(0_u32);

  println!("Highest Ones Roll: {}", max_ones);
  println!("Number of Roll Sessions: {}", step_size * thread_count);
}

// We split this into its own function to neaten up the main function a bit,
// but otherwise it is all the same, as is `QuickRng`.
fn check_n_games(n: u64) -> u32 {
  let mut rng = rand::thread_rng();
  let mut ones = 0;
  let mut max_ones = 0;
  let mut rng1 = QuickRng { state: rng.gen() };
  let mut rng2 = QuickRng { state: rng.gen() };

  // Not checking for if we got enough ones because it is too costly for such
  // a slim chance
  for _ in 0..n {
    // Since we are now rolling 64 random numbers at a time we can only use
    // 3 random numbers before we do something special.
    for _ in 0..3 {
      // By anding two random numbers we have a 25% chance of having a 1 for
      // any bit, therefore the count of ones is the number of "ones rolled"
      // on a four sided dice.
      let state = rng1.get_state() & rng2.get_state();
      ones += state.count_ones();
    }

    // Last one is special because we only check 39 bits
    // (That's what the last & is for)
    let state = rng1.get_state() & rng2.get_state() & 0x7F_FF_FF_FF_FF;
    ones += state.count_ones();

    if ones > max_ones {
        max_ones = ones;
    }
    ones = 0;
  }
  return max_ones;
}
```

This gave us a `5.1×` speedup for basically free.

### LTO, like the DMV but faster

Now we are going to do some tings a bit outside of the written code, and start telling the compiler that we can wait longer if it can give us faster code. To do this we need to modify our `cargo.toml`:

```toml
# ...
[profile.release]
lto = "fat"
# ...
```

Yeah, that's it, and it gave us a `1.2×` speedup, not much, but in terms of time spent implementing to runtime length it is easily the second best optimisation made in the whole project.

### If x86 was so good, how come there wasn't ever a x87?

The highest runtime speedup to implementation time optimisation was easily telling the compiler to write the assembly code specially for our CPU, using instructions that may be specific to its architecture. All we need to do for that is running the build command like this `RUSTFLAGS="-C target-cpu=native" cargo ...`. Giving us a further `1.3×` speedup, taking us back under a second to run on my laptop.

## Is the past tense of simp SIMD?

All this assembly focused optimisation made me wonder. Could my code benefit from [SIMD](https://en.wikipedia.org/wiki/Single_instruction,_multiple_data). It turns out it might.

If you remember our PRNG code looks something like this:

```rust
impl QuickRng {
  pub fn next_state(&mut self) {
    self.state ^= self.state << 7;
    self.state ^= self.state >> 9;
  }

  pub fn get_state(&mut self) -> u64 {
    let result = self.state;
    self.next_state();
    return result;
  }
}
```

Since we call `next_state` on two different objects sequentially we end up doing something like this:

```rust
state_a ^= state_a << 7;
state_a ^= state_a >> 9;


state_b ^= state_b >> 7;
state_b ^= state_b >> 9;
```

But the CPU would much prefer something like this:

```rust
state_a ^= state_a << 7;
state_b ^= state_b >> 7;

state_a ^= state_a >> 9;
state_b ^= state_b >> 9;
```

That way the repeated instructions occur one after another. Unfortunately this will mean we have to do a massive rework of our PRNG so that both states are stored in the one object.

```rust
struct QuickerRng {
  state_1: u64,
  state_2: u64,
}

impl QuickerRng {
  fn new(mut rng: ThreadRng) -> Self {
    Self {
      state_1: rng.gen(),
      state_2: rng.gen(),
    }
  }

  fn next_state(&mut self) {
    self.state_1 ^= self.state_1 << 7;
    self.state_2 ^= self.state_2 << 7;

    self.state_1 ^= self.state_1 >> 9;
    self.state_2 ^= self.state_2 >> 9;
  }

  fn get_chances(&self) -> u64 {
    self.state_1 & self.state_2
  }
}
```

Now the speedup may not have been due to SIMD, it could have been that it didn't need to allocate as much memory, fewer stack pops and pushes, or any number of other possibilities. But the results speak for themselves: `1.09×` speedup, and under half a second now on my laptop.

## Divide and conquer

What if I told you that the multiplexing that we did to speed up each of the turns could also speed up the games at the cost of higher memory usage and simulating slightly more games? It's possible, it just takes some data science.

Since the PRNG depends on two unique states to generate random numbers, let's see how may states we actually need to generate in order to have enough unique numbers to simulate at least a trillion.

We just need to look at the initial states since they are [deterministic](https://en.wikipedia.org/wiki/Deterministic_algorithm). Since we know that we need at least one trillion unique combinations of two states we actually have enough information to solve for how many initial states we need.

$$
\binom{x}{2} = 1,000,000,000 \text{ where } x > 0
$$

Unfortunately this gives us the answer $$x = \frac{1}{2} (1 + 3 \sqrt{888,888,889})$$ or approximately `44721.86` which is not a whole number<sup>\[[citation needed](https://whatif.xkcd.com/)\]</sup>, so we can instead build `44722` half solutions, and this would work well if we were still running a single-threaded application. Since we have a multithreaded application, and on my system there are 12 threads, we will be looking for $$\binom{x}{2} > \frac{1,000,000,000}{12}$$ $$\lceil x\rceil = 12911$$ and giving us an overcount of $$\binom{12911}{2} \times 12 - 1,000,000,000 = 86,060$$. This means that this solution could work if the speedup is at least `1.0000086×`, and since the optimistic speedup is $$\frac{1,000,000,000}{44722} \approx 22360$$ that is a risk I am willing to take.

Here is the new code taking advantage of permutations:

```rust
fn main() {
  const THREADS: u64 = 12;
  const STEP_SIZE: u64 = 83340505; // binom(12911, 2)

  // Generate 12 threads
  let results = (0..THREADS)
    .into_par_iter()
    // For each of them play games equal to
    // 1,000,000,000/threads + 1 (to make sure we play AT
    // LEAST one billion games)
    .map(|_| check_from_half_games())
    // Find the maximum of the results
    .max()
    // Return 0 if all threads panicked
    .unwrap_or(0);

  println!("Highest Ones Roll: {}", results);
  println!("Number of Roll Sessions: {}", STEP_SIZE * THREADS);
}
```

The only notable change is line 10 where we are now calling this function called `check_from_half_games`, let's take a look at that function:

```rust

fn check_from_half_games() -> u32 {
  // Just a utility function to make calling easier
  play_game_sets(pregenerate_12911_half_games())
}
```

Notice we are pre-generating 12911 half games, this is because with multithreading its not actually going to be $\binom{x}{2}$, it will be $\binom{x}{2} \times \textrm{number of threads}$ hence why `THREADS` is now a `const`. let's look into these half game generations:

```rust
/// By generating this specific number of sets of random numbers we can reuse them
/// by combining them with different random number sets, because
/// binom(12911,2) * 12 (number of cores) > 10^9 (number of games),
/// 1_000_086_060 specifically.
pub fn pregenerate_12911_half_games() -> [[u64; 4]; 12_911] {
  // Allocate memory for the output
  let mut results: [[u64; 4]; 12911] = [[0; 4]; 12911];

  // Generate "true" random numbers occasionally
  let mut rng = rand::thread_rng();

  // Each time generate four states so we have at least 231 bits of data.
  let mut inner: [u64; 4] = [0; 4];

  for i in 0..1290 {
    // Use random_number to reduce calls to rng.gen()
    let mut random_number: u64 = rng.gen();
    inner[0] = random_number;

    // Just an unwrapped for loop
    random_number ^= random_number << 7;
    random_number ^= random_number >> 9;
    inner[1] = random_number;

    random_number ^= random_number << 7;
    random_number ^= random_number >> 9;
    inner[2] = random_number;

    random_number ^= random_number << 7;
    random_number ^= random_number >> 9;
    inner[3] = random_number;

    results[i] = inner;
  }

  results
}
```

Finally here is that `play_game_sets` function.

```rust
/// Play each unique pairing of two random half games. Returning the
/// maximum number of ones in a game, and the number of games played.
pub fn play_game_sets(half_games: [[u64; 4]; 12_911]) -> u32 {
  let mut max_ones = 0;

  // For each game aside from the last one.
  for i in 0..12910 {
    let game_a = half_games[i];

    // For each game in the remaining list after i.
    for j in (i + 1)..12911 {
      let game_b = half_games[j];

      // This is basically the same as the previous version's `play_n_games`
      let mut ones = (game_a[0] & game_b[0]).count_ones();
      ones += (game_a[1] & game_b[1]).count_ones();
      ones += (game_a[2] & game_b[2]).count_ones();
      ones += (game_a[3] & game_b[3] & 0x7F_FF_FF_FF_FF).count_ones();

      if ones > max_ones {
          max_ones = ones;
      }
    }
  }

  max_ones
}
```

This implementation had the unexpected advantage of reducing the average result to something more in line with the expected outcomes, probably due to fewer PRNG cycles between `rng.gen()` calls. While also giving us a `1.89×` speedup.

## Summary

Overall we have taken this solution from taking an estimated 1500 seconds to simulate a billion games all the way down to about 0.3 seconds, a speed improvement of over `5000×`, and approaching `2,500,000×` improvement over the original Python implementation.
